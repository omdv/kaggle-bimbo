{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductId                                             9853\n",
       "product_name         Pasteles yo Galletas 2a 500g MLA 9853\n",
       "product_shortname             Pasteles yo Galletas 2a 500g\n",
       "brand                                                  MLA\n",
       "weight                                                 500\n",
       "pieces                                                 NaN\n",
       "volume                                                 NaN\n",
       "product_type                 [u'pastel', u'yo', u'gallet']\n",
       "weight_per_piece                                       NaN\n",
       "has_choco                                            False\n",
       "has_vanilla                                          False\n",
       "has_multigrain                                       False\n",
       "has_promotion                                        False\n",
       "cluster                                                 30\n",
       "product_type_len                                         3\n",
       "Name: 368, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin = pd.read_csv('processed/processed_products_averaged.csv')\n",
    "# print df_origin\n",
    "# print df_origin.product_type.unique().shape[0]\n",
    "df_origin.iloc[368]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\\\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\\\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\\\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\\\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\\\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'AdjDemandMean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0fb07be87a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0midx_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_origin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_origin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdjDemandMean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0midx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_origin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_origin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdjDemandMean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_origin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Feature processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2358\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[1;32m-> 2360\u001b[1;33m                                  (type(self).__name__, name))\n\u001b[0m\u001b[0;32m   2361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'AdjDemandMean'"
     ]
    }
   ],
   "source": [
    "idx_predict = df_origin[df_origin.AdjDemandMean.isnull()].index\n",
    "idx_train = df_origin[df_origin.AdjDemandMean.notnull()].index\n",
    "df = df_origin.fillna(0)\n",
    "\n",
    "# Feature processing\n",
    "[df['productTypeFct'],typeFct] = pd.factorize(df.product_type)\n",
    "[df['brandFct'],brandFct] = pd.factorize(df.brand)\n",
    "df['has_choco'] = df.apply(lambda x: 1 if x.has_choco else 0,axis=1)\n",
    "df['has_multigrain'] = df.apply(lambda x: 1 if x.has_multigrain else 0,axis=1)\n",
    "df['has_vanilla'] = df.apply(lambda x: 1 if x.has_vanilla else 0,axis=1)\n",
    "df['has_promotion'] = df.apply(lambda x: 1 if x.has_promotion else 0,axis=1)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "df['weight_s'] = scaler.fit_transform(df['weight'].reshape(-1,1))\n",
    "df['volume_s'] = scaler.fit_transform(df['volume'].reshape(-1,1))\n",
    "df['wpp_s'] = scaler.fit_transform(df['weight_per_piece'].reshape(-1,1))\n",
    "df['pieces_s'] = scaler.fit_transform(df['pieces'].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# empty values to predict\n",
    "df_to_predict = df.ix[idx_predict].copy(deep=True)\n",
    "df_train = df.ix[idx_train].copy(deep=True)\n",
    "\n",
    "#split into training and test datasets\n",
    "df_train = df_train[['product_name','productTypeFct','brandFct','weight_s','volume_s','pieces_s',\\\n",
    "          'wpp_s','has_choco','has_vanilla','has_multigrain','has_promotion','cluster',\\\n",
    "          'AdjDemandMean','AdjDemandMeanScaled']]\n",
    "\n",
    "# X - all columns except name and y-vectors\n",
    "X = df_train.loc[:,'productTypeFct':'cluster']\n",
    "\n",
    "# choose y - either Median or Mean\n",
    "y = df_train.loc[:,'AdjDemandMean']\n",
    "\n",
    "# split into validation and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "n_est = 5\n",
    "model = RandomForestRegressor(n_estimators = n_est)\n",
    "title = 'Random forest: ' + str(n_est)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# plot the learning curve\n",
    "plot_learning_curve(model, title, X_train, y_train, ylim=(0.0, 1.01), cv=5, n_jobs=4)\n",
    "\n",
    "# Plot feature importance\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, X.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "# Evaluate quality of prediction on test dataset\n",
    "y_pred_s = model.predict(X_test)\n",
    "global_median = y.median()\n",
    "global_mean = y.mean()\n",
    "mse_pred = np.sqrt(np.sum((y_test-y_pred_s)**2)/2/y_test.shape[0])\n",
    "mse_median = np.sqrt(np.sum((y_test-global_median)**2)/2/y_test.shape[0])\n",
    "mse_mean = np.sqrt(np.sum((y_test-global_mean)**2)/2/y_test.shape[0])\n",
    "print \"Pred: {:10.4f}, Median: {:10.4f}, Mean: {:10.4f}\".format(mse_pred,mse_median,mse_mean)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(y_test,y_pred_s,'ro')\n",
    "ax.plot([0,100],[global_median,global_median],'b--')\n",
    "xt = ax.set_xlim([0,8])\n",
    "yt = ax.set_ylim([0,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predict new values\n",
    "X_predict = df_to_predict[X_train.columns]\n",
    "y_predict = np.exp(model.predict(X_predict))-1.0\n",
    "# y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new = df_origin\n",
    "df_new.loc[idx_predict,'AdjDemandMean'] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_new.loc[:,'ProductId':].set_index('ProductId').to_csv('processed/predicted_products.csv')\n",
    "df_to_predict.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
